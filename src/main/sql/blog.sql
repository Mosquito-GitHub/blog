/*
SQLyog Ultimate v11.33 (64 bit)
MySQL - 5.7.18-log : Database - blog
*********************************************************************
*/

/*!40101 SET NAMES utf8 */;

/*!40101 SET SQL_MODE=''*/;

/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;
CREATE DATABASE /*!32312 IF NOT EXISTS*/`blog` /*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_bin */;

USE `blog`;

/*Table structure for table `article` */

DROP TABLE IF EXISTS `article`;

CREATE TABLE `article` (
  `id` bigint(13) NOT NULL AUTO_INCREMENT COMMENT '博文id',
  `author` varchar(20) DEFAULT NULL COMMENT '作者',
  `title` varchar(60) DEFAULT NULL COMMENT '标题',
  `modifytime` datetime DEFAULT NULL COMMENT '最后修改时间',
  `createtime` date DEFAULT NULL COMMENT '创建时间',
  `keyword` varchar(50) DEFAULT NULL COMMENT '关键字',
  `tags` varchar(50) DEFAULT NULL COMMENT '标签',
  `context` text COMMENT '内容',
  `abstractcontext` text COMMENT '内容摘要',
  `readnum` int(11) DEFAULT '0' COMMENT '浏览次数',
  `guestip` char(20) DEFAULT NULL COMMENT '最后访问者ip',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=100021 DEFAULT CHARSET=utf8;

/*Data for the table `article` */

insert  into `article`(`id`,`author`,`title`,`modifytime`,`createtime`,`keyword`,`tags`,`context`,`abstractcontext`,`readnum`,`guestip`) values (100000,'mosquito','这里是标题','2017-06-19 09:20:35','2017-06-19','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p>','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。',303,NULL),(100001,'mosquito','这里是标题1','2017-06-18 09:20:35','2017-06-18','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p>','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。',301,NULL),(100002,'mosquito','这里是标题2','2017-06-17 09:20:35','2017-06-17','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p>','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p>',300,NULL),(100003,'mosquito','这里是标题3','2017-06-16 09:20:35','2017-06-16','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p>','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p>',300,NULL),(100004,'mosquito','这里是标题4','2017-06-15 09:20:35','2017-06-15','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p><img alt=\"\" src=\"img/5.jpg\">','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p>',300,NULL),(100005,'mosquito','这里是标题5','2017-06-14 09:20:35','2017-06-14','测试数据','HTML','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p><p>我两年前徒步过一次，那次走了一个多月，累的半死。这次徒步强度相对较小，我不再带帐篷睡袋，轻装上路，这也就等于去不了太偏远、远离城镇的地方。</p><p>人多的地方没有风景，最好走郊区、农村或者山野。当然，安全还是要放在第一位的。如果有骑行或自驾游的网友，求捎带。</p><p>准备苦行，一人一包再次行走在天地之间，想想还有点小鸡冻。</p><img alt=\"\" src=\"img/5.jpg\">','<p>在电脑前做久了，总感觉眼睛发涩、胳膊腿儿变细，肚子上若隐若现的腹肌也彻底转换为了囊肉。为了增强体质，我要来一次徒步，从重庆老同学@强仔那出发，一路西行。</p>',304,NULL),(100016,'mosquito','在Hadoop上运行Docker容器的六大陷阱','2017-06-22 10:12:58','2017-06-22','hadoop、docker','技术','<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">尽管在Hadoop上集成了容器负载的潜在价值，目前任职于Cloudera的Daniel Templeton仍然建议在部署Docker容器之前，等待Hadoop 3.0版本引入安全问题和其他问题的注意事项。在上周于迈阿密召开的北美Apache大会上，Daniel在演讲中表示：“它的潜在价值确实很大，但Hadoop3.0发布前，它仍然解决不了你的问题。容器很酷，但你确实还无法使用它。”</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">作为Cloudera 的YARN项目中的一名软件工程师，Templeton曾深入了解过由Hadoop Linux Container Executor提供的Docker支持（下载），也曾经探讨过何时会出现更好的选择。他曾在探讨中坚持地认为是Docker应用在Hadoop之上，而不是Hadoop应用在Docker上。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">“如果你也有一个Hadoop集群，你会和我一样，想在Docker容器里执行工作负载的。”</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">虽然Hadoop的YARN调度引擎目前支持Docker作为已提交应用的执行引擎，但当你在现有版本的Hadoop中执行它的时候，还是需要提前了解那些“坑”。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱一：Docker容器中必须开放应用权限</span>&nbsp;<br/>目前，当你在运行Docker容器时，需要指定一个用户运行它。如果你指定的是用户ID而不是用户名，假如这个用户ID不存在，它也会自动为你创建用户。这种重新映射在遇到大量image的时候是无法正常工作的，也就意味着用户必须事先指定，如若不然，你将无法访问任何内容，也不能启动脚本和记录日志，将完全处于宕掉的状态。&nbsp;<br/>这个问题目前还没有一个很好的解决办法，如果你有好的想法，欢迎到YARN-4266上参与讨论（<a href=\"https://issues.apache.org/jira/browse/YARN-4266\" style=\"box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration-line: none;\">https://issues.apache.org/jira/browse/YARN-4266</a>）。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498097529676071839.png\" alt=\"图片描述\" title=\"\" width=\"727\" height=\"468\"/><br/>图自Daniel Templeton的演讲内容</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱二：Docker容器和运行环境之间不独立</span>&nbsp;<br/>可移植性是Docker容器最主要的特性之一，但运行于Hadoop的时候Docker的可移植性却不怎么好。当你想访问HDFS或者当你需要反译令牌，又或者当你需要像MapReduce这样的框架，亦或你想做Spark的时候，你必须得拥有image中的代码文件才可以实现。因此Hadoop的版本必须升级。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">升级Hadoop版本的补丁程序可以在YARN-5534上下载（下载地址：<a href=\"https://issues.apache.org/jira/browse/YARN-5534\" style=\"box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration-line: none;\">https://issues.apache.org/jira/browse/YARN-5534</a>）。该补丁程序允许安装被列为白名单的存储卷，且开放管理员权限。当你拥有管理员权限，不仅这些目录可以被允许安装到Docker容器中，而且可以指定要挂载的目录。但需要注意的是，千万不要挂载任何可能会搞砸的东西。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱三：image太大就会报错</span>&nbsp;<br/>当执行程序的时候，docker_run将隐含地从repo中拉出图像，虽然Spark和MapReduce都有10分钟的超时时间，但如果图像太大，网络下载时间超过了10分钟，程序就会报错。假如持续地重新提交程序，导致的最终结果将会是程序处在某个已经尝试过的节点上并运行。目前针对这种图像报错，YARN上对图像缓存暂无有效的解决方法。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱四：不支持安全回收</span>&nbsp;<br/>Docker会将访问了client_config中安全备份的.docker / config.json文件进行存储备份，这个应该众所周知。这意味着当你访问安全备份时，无论从哪个节点管理器登录，你都会受到用户主目录中.docker / config.json文件的约束。恐怕这种限制没人能接受。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱五：网络只有最基本的支持</span>&nbsp;<br/>众所周知，当应用Kubernetes、Mesos这类容器管理工具的时候，网络很容易就得到实现，CNS也能得到处理。但YARN却提供不了这样的网络管理服务。YARN没有内置的端口映射的概念，网络也没有真正的自动化管理。相反，如果你想请求访问网络，你只能通过所有节点管理器上的Docker来显式创建网络。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">陷阱六：具备较大的安全隐患</span>&nbsp;<br/>Docker在Hadoop上运行是有安全隐患的。为什么这么说？Docker中的一个特权容器可以窥探底层操作系统，访问斜线进程和设备。假如是以root权限运行在容器当中，那么在底层操作系统中很有机会执行非常可怕的操作。当这种情况发生的时候，YARN目前是无法指定到用户的。虽然可以通过将其关闭或限制到某一特定用户组的做法来控制它，但这个安全隐患的问题必须得到重视。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">Hadoop 3.0</span>&nbsp;<br/>虽然Hadoop2.8中存在Docker的修复程序，但仍然不够用。在本次更新版本中，Hadoop3.0新增功能点：&nbsp;<br/>•支持本地化的文件目录作为卷进行安装；&nbsp;<br/>•支持cgroups；&nbsp;<br/>•支持不同的网络选项；&nbsp;<br/>•支持文档；</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">据悉Hadoop3.0将很可能在年底发布，其主要功能Hbase擦除编码将得到改进，并将为用户提供1.5倍的存储空间。这意味着可以节省用户一半的硬盘成本，并对YARN和MapReduce的用户产生巨大的影响。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">目前Hadoop3.0的项目一直与雅虎，Twitter和微软等主要用户合作，确保与现有系统的兼容性，并且不会出现任何痛苦的滚动升级。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\"><span style=\"box-sizing: border-box; font-weight: 700;\">原文：</span><a href=\"https://thenewstack.io/docker-hadoop-theres-good-bad-ugly/\" style=\"box-sizing: border-box; background-color: transparent; color: rgb(51, 122, 183); text-decoration-line: none;\">https://thenewstack.io/docker-hadoop-theres-good-bad-ugly/</a></p><p><br/></p>','<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">尽管在Hadoop上集成了容器负载的潜在价值，目前任职于Cloudera的Daniel Templeton仍然建议在部署Docker容器之前，等待Hadoop 3.0版本引入安全问题和其他问题的注意事项。在上周于迈阿密召开的北美Apache大会上，Daniel在演讲中表示：“它的潜在价值确实很大，但Hadoop3.0发布前，它仍然解决不了你的问题。容器很酷，但你确实还无法使用它。”</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">作为Cloudera 的YARN项目中的一名软件工程师，Templeton曾深入了解过由Hadoop Linux Container Executor提供的Docker支持（下载），也曾经探讨过何时会出现更好的选择。他曾在探讨中坚持地认为是Docker应用在Hadoop之上，而不是Hadoop应用在Docker上。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">“如果你也有一个Hadoop集群，你会和我一样，想在Docker容器里执行工作负载的。”</p>',0,NULL),(100017,'mosquito','HBase thrift/thrift2 使用指南','2017-06-22 10:16:52','2017-06-22','hbase','技术','<p><span style=\"box-sizing: border-box; font-weight: 700; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif;\">摘要：</span><span style=\"color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; background-color: rgb(249, 249, 249);\">&nbsp;Thrift server简介 Thrift server是HBase中的一种服务，主要用于对多语言API的支持。基于Apache Thrift（多语言支持的通信框架）开发，目前有两种版本thrift和thrift2。</span></p><p><span style=\"color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; background-color: rgb(249, 249, 249);\"></span></p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server简介</h1><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server是HBase中的一种服务，主要用于对多语言API的支持。基于<a href=\"https://thrift.apache.org/\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">Apache Thrift</a>（多语言支持的通信框架）开发，目前有两种版本<a href=\"https://github.com/apache/hbase/blob/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">thrift</a>和<a href=\"https://github.com/apache/hbase/blob/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift2/hbase.thrift\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">thrift2</a>。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">thrift2是当时为了适应新的Java API，提出来的。由于种种原因，thrift2没有完美兼容并替代thrift，所有就留下了两个版本。</p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift 和 Thrift2 的区别</h1><ul style=\"box-sizing: border-box; margin-bottom: 10px; padding: 0px 0px 0px 40px; list-style-position: inside; list-style-image: initial; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>接口设计上Thrift2要比Thrfit更优雅，或者说和现在的API更贴近。比如两者的get接口：</p></li></ul><pre style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; word-wrap: break-word; overflow: auto; font-size: 13px; border-radius: 2px; line-height: 1.42857; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; word-break: break-all; color: rgb(51, 51, 51); border: none; background-color: rgb(255, 255, 255);\">&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Thrift2&nbsp;的get接口，传入TGet（对应Java&nbsp;API种的Get类)\n&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;用过Java&nbsp;API的同学看起来应该会更亲切\n&nbsp;&nbsp;&nbsp;&nbsp;TResult&nbsp;get(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;the&nbsp;table&nbsp;to&nbsp;get&nbsp;from&nbsp;*/\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1:&nbsp;required&nbsp;binary&nbsp;table,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;the&nbsp;TGet&nbsp;to&nbsp;fetch&nbsp;*/\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2:&nbsp;required&nbsp;TGet&nbsp;tget\n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;throws&nbsp;(1:&nbsp;TIOError&nbsp;io)</pre><pre style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; word-wrap: break-word; overflow: auto; font-size: 13px; border-radius: 2px; line-height: 1.42857; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; word-break: break-all; color: rgb(51, 51, 51); border: none; background-color: rgb(255, 255, 255);\">&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Thrift&nbsp;的get接口，没有TGet这些包装，比较裸\n&nbsp;&nbsp;&nbsp;&nbsp;list&lt;TCell&gt;&nbsp;get(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;name&nbsp;of&nbsp;table&nbsp;*/\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1:Text&nbsp;tableName,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;row&nbsp;key&nbsp;*/\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2:Text&nbsp;row,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;column&nbsp;name&nbsp;*/&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3:Text&nbsp;column,&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/**&nbsp;Get&nbsp;attributes&nbsp;*/\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4:map&lt;Text,&nbsp;Text&gt;&nbsp;attributes\n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;throws&nbsp;(1:IOError&nbsp;io)</pre><ul style=\"box-sizing: border-box; margin-bottom: 10px; padding: 0px 0px 0px 40px; list-style-position: inside; list-style-image: initial; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>Thrift2没有DDL方面的接口，所以现在<a href=\"http://gethue.com/\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">Hue</a>还是用Thrift的接口。如果你只想读写数据，建议用Thrift2。</p></li></ul><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server原理</h1><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">Thrfit其实就是个代理，你的请求发到Thrift server上后，server通过Java API再帮你访问HBase。<br/><a target=\"_blank\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); transition: color 0.2s; background: 0px 0px;\"><img src=\"https://yqfile.alicdn.com/1206252b15543063a28d3d511073512dbac937a4.png\" alt=\"Thrift_server\" title=\"Thrift_server\"/></a><br/>Thrift实现类是<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">org.apache.hadoop.hbase.thrift.ThriftServer</code>，thrift2的实现类是<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">org.apache.hadoop.hbase.thrift2.ThriftServer</code>。它们访问HBase使用的也是普通的HBase client API，所以当你的请求到达Thrift server后，它通过client API去帮你定位数据，然后读取数据。这么来看，Thrift Server比较灵活，你可以部署在客户机上，也可以独立部署一个thrift集群。</p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server 参数选择</h1><ul style=\"box-sizing: border-box; margin-bottom: 10px; padding: 0px 0px 0px 40px; list-style-position: inside; list-style-image: initial; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>TServer的选择。这是Thrift框架server端处理模型的选择。有三种，<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">TNonblockingServer</code>，<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">THsHaServer</code>，<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">TThreadPoolServer</code>。可以通过启动命令参数指定，具体运行<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">./bin/hbase thrift</code>可以看到命令帮助(or&nbsp;<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">./bin/hbase thrift2</code>)。默认是用<code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">TThreadPoolServer</code>，建议就不用改了，除非你特别了解你的场景。关于这几种模型的区别，性能对比可以看这篇<a href=\"https://github.com/m1ch1/mapkeeper/wiki/Thrift-Java-Servers-Compared\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">文章</a>。</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.regionserver.thrift.compact</code>&nbsp;是否使用Thrift TCompactProtocol，默认false。如果你每列数据比较大，可以试着开启，减少带宽。</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.thrift.connection.cleanup-interval</code>&nbsp;thrift server清理与HBase连接的周期，与HBase的是一个长连接，默认10秒</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.thrift.connection.max-idletime</code>&nbsp;如果与HBase的长连接超过这个时间没有被使用，则会被清理，默认10分钟</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.thrift.minWorkerThreads</code>&nbsp;TThreadPoolServer的线程池中的corePoolSize，也就是即便空闲时候保持的线程数，默认16。</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.thrift.maxWorkerThreads</code>&nbsp;TThreadPoolServer的线程池中的maximumPoolSize，默认1000。这个会影响server最大处理能力，需要根据硬件衡量。</p></li><li><p><code style=\"box-sizing: border-box; margin: 0px; padding: 2px 4px; font-size: 14.4px; border-radius: 2px; font-family: Menlo, Monaco, Consolas, &quot;Courier New&quot;, monospace; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); white-space: nowrap;\">hbase.thrift.maxQueuedRequests</code>&nbsp;TThreadPoolServer的线程池队列长度上限，超过这个值时会去创建一个新的线程处理请求（前提是没有达到maxWorkerThreads，否则拒绝请求）</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\"><em style=\"box-sizing: border-box; font-weight: inherit;\">注：</em>上述最后三个值对thrift2无效。1.3之前的版本中，thrift2无法设定这些值。2.0版本中在thrift2启动命令里通过指定&#39;w&#39;选项来设置maxWorkerThreads。具体可以运行上文中提到的命令，查看是否支持&#39;w&#39;选项，如果不支持，默认max=int最大值。</p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift部署模式</h1><ul style=\"box-sizing: border-box; margin-bottom: 10px; padding: 0px 0px 0px 40px; list-style-position: inside; list-style-image: initial; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>集群模式&nbsp;<a target=\"_blank\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); transition: color 0.2s; background: 0px 0px;\"><img src=\"https://yqfile.alicdn.com/de5eb77c70c1c4e0bcdaa6f731c78b4aef4813a5.png\" alt=\"thrift_\" title=\"thrift_\"/></a></p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">这是最常见的模式，集群模式中的thrift建议不要和RS或者DN混部署。并且如果你使用集群模式的部署方案，你的client端不要去维护长连接。因为如果你维护一个长连接，负载均衡就会失效，如果thrift集群重启，大部分连接会连上第一个起来的thrfit server。</p><ul style=\"box-sizing: border-box; margin-bottom: 10px; padding: 0px 0px 0px 40px; list-style-position: inside; list-style-image: initial; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>本地模式&nbsp;<a target=\"_blank\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); transition: color 0.2s; background: 0px 0px;\"><img src=\"https://yqfile.alicdn.com/31f3745fea2bf7dc5b281a2847be49dc883f111b.png\" alt=\"thrift_\" title=\"thrift_\"/></a></p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">本地模式就是在每个客户机上起一个client，这个客户机独享一个thrift。优点是部署简单，网络开销少。并且这种模式可以使用长连接，自己维护TTransport池。对于持续的写入或者读取，效果要比短连接好很多。HBase IPC本身也是维护一个长连接。缺点是，可靠性略差，如果thrift server挂了的话。但本身如果是多Client，其实也无所谓。</p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">使用示例</h1><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">直接参考这篇博文吧：<a href=\"http://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">http://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/</a></p><p><span style=\"color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; background-color: rgb(249, 249, 249);\"><br/></span><br/></p>','<p><span style=\"box-sizing: border-box; font-weight: 700; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif;\">摘要：</span><span style=\"color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; background-color: rgb(249, 249, 249);\">&nbsp;Thrift server简介 Thrift server是HBase中的一种服务，主要用于对多语言API的支持。基于Apache Thrift（多语言支持的通信框架）开发，目前有两种版本thrift和thrift2。</span></p><p><span style=\"color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; background-color: rgb(249, 249, 249);\"></span></p><h1 style=\"box-sizing: border-box; margin: 20px 0px 10px; padding: 0px; font-size: 36px; font-weight: 500; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; line-height: 1.1; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server简介</h1><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; padding: 0px; color: rgb(51, 51, 51); font-family: PingFangSC, &quot;helvetica neue&quot;, &quot;hiragino sans gb&quot;, arial, &quot;microsoft yahei ui&quot;, &quot;microsoft yahei&quot;, simsun, sans-serif; white-space: normal; background-color: rgb(255, 255, 255);\">Thrift server是HBase中的一种服务，主要用于对多语言API的支持。基于<a href=\"https://thrift.apache.org/\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">Apache Thrift</a>（多语言支持的通信框架）开发，目前有两种版本<a href=\"https://github.com/apache/hbase/blob/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">thrift</a>和<a href=\"https://github.com/apache/hbase/blob/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift2/hbase.thrift\" style=\"box-sizing: border-box; color: rgb(0, 193, 222); text-decoration-line: none; transition: color 0.2s; background: 0px 0px;\">thrift2</a>。</p>',0,NULL),(100018,'mosquito','Hadoop生态系统的详细介绍','2017-06-22 10:19:18','2017-06-22','hadoop','技术','<p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; white-space: normal; background-color: rgb(255, 255, 255); text-align: center;\"><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498097942404045201.jpg\" alt=\"大数据\" width=\"609\"/></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>1、Hadoop生态系统概况</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hadoop是一个能够对大量数据进行分布式处理的软件框架。具有可靠、高效、可伸缩的特点。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hadoop的核心是HDFS和MapReduce，hadoop2.0还包括YARN。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　下图为hadoop的生态系统：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; white-space: normal; background-color: rgb(255, 255, 255); text-align: center;\"><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498097942555072927.png\" alt=\"大数据\" width=\"609\"/></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>2、HDFS(Hadoop分布式文件系统)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　源自于Google的GFS论文，发表于2003年10月，HDFS是GFS克隆版。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　是Hadoop体系中数据存储管理的基础。它是一个高度容错的系统，能检测和应对硬件故障，用于在低成本的通用硬件上运行。HDFS简化了文件的一致性模型，通过流式数据访问，提供高吞吐量应用程序数据访问功能，适合带有大型数据集的应用程序。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　HDFS这一部分主要有一下几个部分组成：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(1)、Client：切分文件;访问HDFS;与NameNode交互，获取文件位置信息;与DataNode交互，读取和写入数据。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(2)、NameNode：Master节点，在hadoop1.X中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户端请求。对于大型的集群来讲，Hadoop1.x存在两个最大的缺陷：1)对于大型的集群，namenode的内存成为瓶颈，namenode的扩展性的问题;2)namenode的单点故障问题。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　针对以上的两个缺陷，Hadoop2.x以后分别对这两个问题进行了解决。对于缺陷1)提出了Federation namenode来解决，该方案主要是通过多个namenode来实现多个命名空间来实现namenode的横向扩张。从而减轻单个namenode内存问题。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　针对缺陷2)，hadoop2.X提出了实现两个namenode实现热备HA的方案来解决。其中一个是处于standby状态，一个处于active状态。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(3)、DataNode：Slave节点，存储实际的数据，汇报存储信息给NameNode。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(4)、Secondary NameNode：辅助NameNode，分担其工作量;定期合并fsimage和edits，推送给NameNode;紧急情况下，可辅助恢复NameNode，但Secondary NameNode并非NameNode的热备。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　目前，在硬盘不坏的情况，我们可以通过secondarynamenode来实现namenode的恢复。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>3、Mapreduce(分布式计算框架)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　源自于google的MapReduce论文，发表于2004年12月，Hadoop MapReduce是google MapReduce 克隆版。MapReduce是一种计算模型，用以进行大数据量的计算。其中Map对数据集上的独立元素进行指定的操作，生成键-值对形式中间结果。Reduce则对中间结果中相同“键”的所有“值”进行规约，以得到最终结果。MapReduce这样的功能划分，非常适合在大量计算机组成的分布式并行环境里进行数据处理。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　MapReduce计算框架发展到现在有两个版本的MapReduce的API，针对MR1主要组件有以下几个部分组成：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(1)、JobTracker：Master节点，只有一个，主要任务是资源的分配和作业的调度及监督管理，管理所有作业，作业/任务的监控、错误处理等;将任务分解成一系列任务，并分派给TaskTracker。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(2)、TaskTracker：Slave节点，运行Map Task和Reduce Task;并与JobTracker交互，汇报任务状态。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(3)、Map Task：解析每条数据记录，传递给用户编写的map(),并执行，将输出结果写入本地磁盘。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　(4)、Reducer Task：从Map Task的执行结果中，远程读取输入数据，对数据进行排序，将数据按照分组传递给用户编写的reduce函数执行。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　在这个过程中，有一个shuffle过程，对于该过程是理解MapReduce计算框架是关键。该过程包含map函数输出结果到reduce函数输入这一个中间过程中所有的操作，称之为shuffle过程。在这个过程中，可以分为map端和reduce端。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Map端：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　1) 输入数据进行分片之后，分片的大小跟原始的文件大小、文件块的大小有关。每一个分片对应的一个map任务。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　2) map任务在执行的过程中，会将结果存放到内存当中，当内存占用达到一定的阈值(这个阈值是可以设置的)时，map会将中间的结果写入到本地磁盘上，形成临时文件这个过程叫做溢写。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　3) map在溢写的过程中，会根据指定reduce任务个数分别写到对应的分区当中，这就是partition过程。每一个分区对应的是一个reduce任务。并且在写的过程中，进行相应的排序。在溢写的过程中还可以设置conbiner过程，该过程跟reduce产生的结果应该是一致的，因此该过程应用存在一定的限制，需要慎用。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　4) 每一个map端最后都只存在一个临时文件作为reduce的输入，因此会对中间溢写到磁盘的多个临时文件进行合并Merge操作。最后形成一个内部分区的一个临时文件。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Reduce端：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　1) 首先要实现数据本地化，需要将远程节点上的map输出复制到本地。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　2) Merge过程，这个合并过程主要是对不同的节点上的map输出结果进行合并。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　3) 不断的复制和合并之后，最终形成一个输入文件。Reduce将最终的计算结果存放在HDFS上。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　针对MR2是新一代的MR的API。其主要是运行在Yarn的资源管理框架上。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>4、Yarn(资源管理框架)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　该框架是hadoop2.x以后对hadoop1.x之前JobTracker和TaskTracker模型的优化，而产生出来的，将JobTracker的资源分配和作业调度及监督分开。该框架主要有ResourceManager，Applicationmatser，nodemanager。其主要工作过程如下：其ResourceManager主要负责所有的应用程序的资源分配，ApplicationMaster主要负责每个作业的任务调度，也就是说每一个作业对应一个ApplicationMaster。Nodemanager是接收Resourcemanager 和ApplicationMaster的命令来实现资源的分配执行体。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　ResourceManager在接收到client的作业提交请求之后，会分配一个Conbiner，这里需要说明一下的是Resoucemanager分配资源是以Conbiner为单位分配的。第一个被分配的Conbiner会启动Applicationmaster，它主要负责作业的调度。Applicationmanager启动之后则会直接跟NodeManager通信。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　在YARN中，资源管理由ResourceManager和NodeManager共同完成，其中，ResourceManager中的调度器负责资源的分配，而NodeManager则负责资源的供给和隔离。ResourceManager将某个NodeManager上资源分配给任务(这就是所谓的“资源调度”)后，NodeManager需按照要求为任务提供相应的资源，甚至保证这些资源应具有独占性，为任务运行提供基础的保证，这就是所谓的资源隔离。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　在Yarn平台上可以运行多个计算框架，如：MR，Tez，Storm，Spark等计算，框架。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>　5、Sqoop(数据同步工具)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Sqoop是SQL-to-Hadoop的缩写，主要用于传统数据库和Hadoop之间传输数据。数据的导入和导出本质上是Mapreduce程序，充分利用了MR的并行化和容错性。其中主要利用的是MP中的Map任务来实现并行导入，导出。Sqoop发展到现在已经出现了两个版本，一个是sqoop1.x.x系列，一个是sqoop1.99.X系列。对于sqoop1系列中，主要是通过命令行的方式来操作。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　sqoop1 import原理：从传统数据库获取元数据信息(schema、table、field、field type)，把导入功能转换为只有Map的Mapreduce作业，在mapreduce中有很多map，每个map读一片数据，进而并行的完成数据的拷贝。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　sqoop1 export原理：获取导出表的schema、meta信息，和Hadoop中的字段match;多个map only作业同时运行，完成hdfs中数据导出到关系型数据库中。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Sqoop1.99.x是属于sqoop2的产品，该款产品目前功能还不是很完善，处于一个测试阶段，一般并不会应用于商业化产品当中。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Sqoop工具当中，目前我对它的认识是可能会存在一定的问题是因为当在导入导出的时候，map任务失败了，此时Applicationmaster会重新调度另外一个任务来运行这个失败的任务。但是这可能会存在一个问题就是，在未失败前Map任务所导入的数据与重新调度map任务产生的结果会存在重复的现象。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>6、Mahout(数据挖掘算法库)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Mahout起源于2008年，最初是Apache Lucent的子项目，它在极短的时间内取得了长足的发展，现在是Apache的顶级项目。相对于传统的MapReduce编程方式来实现机器学习的算法时，往往需要话费大量的开发时间，并且周期较长，而Mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Mahout现在已经包含了聚类、分类、推荐引擎(协同过滤)和频繁集挖掘等广泛使用的数据挖掘方法。除了算法，Mahout还包含数据的输入/输出工具、与其他存储系统(如数据库、MongoDB 或Cassandra)集成等数据挖掘支持架构。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　mahout的各个组件下面都会生成相应的jar包。此时我们需要明白一个问题：到底如何使用mahout呢?</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　实际上，mahout只是一个机器学习的算法库，在这个库当中是想了相应的机器学习的算法，如：推荐系统(包括基于用户和基于物品的推荐)，聚类和分类算法。并且这些算法有些实现了MapReduce，spark从而可以在hadoop平台上运行，在实际的开发过程中，只需要将相应的jar包即可。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>7、Hbase(分布式列存数据库)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　源自Google的Bigtable论文，发表于2006年11月，传统的关系型数据库是对面向行的数据库。HBase是Google Bigtable克隆版，HBase是一个针对结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库。和传统关系数据库不同，HBase采用了BigTable的数据模型：增强的稀疏排序映射表(Key/Value)，其中，键由行关键字、列关键字和时间戳构成。HBase提供了对大规模数据的随机、实时读写访问，同时，HBase中保存的数据可以使用MapReduce来处理，它将数据存储和并行计算完美地结合在一起。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hbase表的特点</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　1)、大：一个表可以有数十亿行，上百万列;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　2)、无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　3)、面向列：面向列(族)的存储和权限控制，列(族)独立检索;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　4)、稀疏：空(null)列并不占用存储空间，表可以设计的非常稀疏;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　5)、数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　6)、数据类型单一：Hbase中的数据都是字符串，没有类型。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hbase物理模型</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　每个column family存储在HDFS上的一个单独文件中，空值不会被保存。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Key 和 Version number在每个 column family中均有一份;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　HBase 为每个值维护了多级索引，即：，其物理存储：</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　1、Table中所有行都按照row key的字典序排列;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　2、Table在行的方向上分割为多个Region;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　3、Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region;</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　4、Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　5、Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family;每个Strore又由一个memStore和0至多个StoreFile组成，StoreFile包含HFile;memStore存储在内存中，StoreFile存储在HDFS上。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>8、Zookeeper(分布式协作服务)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　源自Google的Chubby论文，发表于2006年11月，Zookeeper是Chubby克隆版，主要解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Zookeeper的主要实现两步：1)、选举Leader 2)、同步数据。这个组件在实现namenode的HA高可用性的时候，需要用到。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>9、Pig(基于Hadoop的数据流系统)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　由yahoo!开源，设计动机是提供一种基于MapReduce的ad-hoc(计算在query时发生)数据分析工具</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　定义了一种数据流语言—Pig Latin，将脚本转换为MapReduce任务在Hadoop上执行。通常用于进行离线分析。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>10、Hive(基于Hadoop的数据仓库)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　由facebook开源，最初用于解决海量结构化的日志数据统计问题。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hive定义了一种类似SQL的查询语言(HQL),将SQL转化为MapReduce任务在Hadoop上执行。通常用于离线分析。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>　11、Flume(日志收集工具)</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Cloudera开源的日志收集系统，具有分布式、高可靠、高容错、易于定制和扩展的特点。</p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　它将数据从产生、传输、处理并最终写入目标的路径的过程抽象为数据流，在具体的数据流中，数据源支持在Flume中定制数据发送方，从而支持收集各种不同协议数据。同时，Flume数据流提供对日志数据进行简单处理的能力，如过滤、格式转换等。此外，Flume还具有能够将日志写往各种数据目标(可定制)的能力。总的来说，Flume是一个可扩展、适合复杂环境的海量日志收集系统。</p><p><br/></p>','<p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; white-space: normal; background-color: rgb(255, 255, 255); text-align: center;\"><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498097942404045201.jpg\" alt=\"大数据\" width=\"609\"/></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　<strong>1、Hadoop生态系统概况</strong></p><p style=\"color: rgb(51, 51, 51); font-family: tahoma, 宋体; font-size: 14px; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">　　Hadoop是一个能够对大量数据进行分布式处理的软件框架。具有可靠、高效、可伸缩的特点。</p>',2,NULL),(100019,'mosquito','大数据框架对比：Hadoop、Storm、Samza、Spark和Flink','2017-06-22 10:22:04','2017-06-22','大数据','技术','<p style=\"box-sizing: border-box; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal; margin-top: 0px !important;\">大数据是收集、整理、处理大容量数据集，并从中获得见解所需的非传统战略和技术的总称。虽然处理数据所需的计算能力或存储容量早已超过一台计算机的上限，但这种计算类型的普遍性、规模，以及价值在最近几年才经历了大规模扩展。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">在之前的文章中，我们曾经介绍过有关大数据系统的常规概念、处理过程，以及各种专门术语，本文将介绍大数据系统一个最基本的组件：处理框架。处理框架负责对系统中的数据进行计算，例如处理从非易失存储中读取的数据，或处理刚刚摄入到系统中的数据。数据的计算则是指从大量单一数据点中提取信息和见解的过程。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">下文将介绍这些框架：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>仅批处理框架：</p></li><ul style=\"list-style-type: square;\" class=\" list-paddingleft-2\"><li><p>Apache Hadoop</p></li></ul><li><p>仅流处理框架：</p></li><ul style=\"list-style-type: square;\" class=\" list-paddingleft-2\"><li><p>Apache Storm</p></li><li><p>Apache Samza</p></li></ul><li><p>混合框架：</p></li><ul style=\"list-style-type: square;\" class=\" list-paddingleft-2\"><li><p>Apache Spark</p></li><li><p>Apache Flink</p></li></ul></ul><h3 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.43; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.5em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>大数据处理框架是什么？</h3><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\"><span style=\"box-sizing: border-box; font-weight: 700;\">处理框架和处理引擎</span>负责对数据系统中的数据进行计算。虽然“引擎”和“框架”之间的区别没有什么权威的定义，但大部分时候可以将前者定义为实际负责处理数据操作的组件，后者则可定义为承担类似作用的一系列组件。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">例如Apache Hadoop可以看作一种以MapReduce作为默认处理引擎的处理框架。引擎和框架通常可以相互替换或同时使用。例如另一个框架Apache Spark可以纳入Hadoop并取代MapReduce。组件之间的这种互操作性是大数据系统灵活性如此之高的原因之一。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">虽然负责处理生命周期内这一阶段数据的系统通常都很复杂，但从广义层面来看它们的目标是非常一致的：通过对数据执行操作提高理解能力，揭示出数据蕴含的模式，并针对复杂互动获得见解。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">为了简化这些组件的讨论，我们会通过不同处理框架的设计意图，按照所处理的数据状态对其进行分类。一些系统可以用批处理方式处理数据，一些系统可以用流方式处理连续不断流入系统的数据。此外还有一些系统可以同时处理这两类数据。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">在深入介绍不同实现的指标和结论之前，首先需要对不同处理类型的概念进行一个简单的介绍。</p><h3 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.43; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.5em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>批处理系统</h3><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">批处理在大数据世界有着悠久的历史。批处理主要操作大容量静态数据集，并在计算过程完成后返回结果。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">批处理模式中使用的数据集通常符合下列特征…</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>有界：批处理数据集代表数据的有限集合</p></li><li><p>持久：数据通常始终存储在某种类型的持久存储位置中</p></li><li><p>大量：批处理操作通常是处理极为海量数据集的唯一方法</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">批处理非常适合需要访问全套记录才能完成的计算工作。例如在计算总数和平均数时，必须将数据集作为一个整体加以处理，而不能将其视作多条记录的集合。这些操作要求在计算进行过程中数据维持自己的状态。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">需要处理大量数据的任务通常最适合用批处理操作进行处理。无论直接从持久存储设备处理数据集，或首先将数据集载入内存，批处理系统在设计过程中就充分考虑了数据的量，可提供充足的处理资源。由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">大量数据的处理需要付出大量时间，因此批处理不适合对处理时间要求较高的场合。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>Apache Hadoop</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\"><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098095613013129.jpg\" alt=\"\"/></p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Apache Hadoop是一种专用于批处理的处理框架。Hadoop是首个在开源社区获得极大关注的大数据框架。基于谷歌有关海量数据处理所发表的多篇论文与经验的Hadoop重新实现了相关算法和组件堆栈，让大规模批处理技术变得更易用。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">新版Hadoop包含多个组件，即多个层，通过配合使用可处理批数据：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>HDFS：HDFS是一种分布式文件系统层，可对集群节点间的存储和复制进行协调。HDFS确保了无法避免的节点故障发生后数据依然可用，可将其用作数据来源，可用于存储中间态的处理结果，并可存储计算的最终结果。</p></li><li><p>YARN：YARN是Yet Another Resource Negotiator（另一个资源管理器）的缩写，可充当Hadoop堆栈的集群协调组件。该组件负责协调并管理底层资源和调度作业的运行。通过充当集群资源的接口，YARN使得用户能在Hadoop集群中使用比以往的迭代方式运行更多类型的工作负载。</p></li><li><p>MapReduce：MapReduce是Hadoop的原生批处理引擎。</p></li></ul><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>批处理模式</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Hadoop的处理功能来自MapReduce引擎。MapReduce的处理技术符合使用键值对的map、shuffle、reduce算法要求。基本处理过程包括：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>从HDFS文件系统读取数据集</p></li><li><p>将数据集拆分成小块并分配给所有可用节点</p></li><li><p>针对每个节点上的数据子集进行计算（计算的中间态结果会重新写入HDFS）</p></li><li><p>重新分配中间态结果并按照键进行分组</p></li><li><p>通过对每个节点计算的结果进行汇总和组合对每个键的值进行“Reducing”</p></li><li><p>将计算而来的最终结果重新写入 HDFS</p></li></ul><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>优势和局限</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">由于这种方法严重依赖持久存储，每个任务需要多次执行读取和写入操作，因此速度相对较慢。但另一方面由于磁盘空间通常是服务器上最丰富的资源，这意味着MapReduce可以处理非常海量的数据集。同时也意味着相比其他类似技术，Hadoop的MapReduce通常可以在廉价硬件上运行，因为该技术并不需要将一切都存储在内存中。MapReduce具备极高的缩放潜力，生产环境中曾经出现过包含数万个节点的应用。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">MapReduce的学习曲线较为陡峭，虽然Hadoop生态系统的其他周边技术可以大幅降低这一问题的影响，但通过Hadoop集群快速实现某些应用时依然需要注意这个问题。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">围绕Hadoop已经形成了辽阔的生态系统，Hadoop集群本身也经常被用作其他软件的组成部件。很多其他处理框架和引擎通过与Hadoop集成也可以使用HDFS和YARN资源管理器。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>总结</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Apache Hadoop及其MapReduce处理引擎提供了一套久经考验的批处理模型，最适合处理对时间要求不高的非常大规模数据集。通过非常低成本的组件即可搭建完整功能的Hadoop集群，使得这一廉价且高效的处理技术可以灵活应用在很多案例中。与其他框架和引擎的兼容与集成能力使得Hadoop可以成为使用不同技术的多种工作负载处理平台的底层基础。</p><h3 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.43; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.5em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>流处理系统</h3><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">流处理系统会对随时进入系统的数据进行计算。相比批处理模式，这是一种截然不同的处理方式。流处理方式无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">流处理中的数据集是“无边界”的，这就产生了几个重要的影响：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>完整数据集只能代表截至目前已经进入到系统中的数据总量。</p></li><li><p>工作数据集也许更相关，在特定时间只能代表某个单一数据项。</p></li><li><p>处理工作是基于事件的，除非明确停止否则没有“尽头”。处理结果立刻可用，并会随着新数据的抵达继续更新。</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">流处理系统可以处理几乎无限量的数据，但同一时间只能处理一条（真正的流处理）或很少量（微批处理，Micro-batch Processing）数据，不同记录间只维持最少量的状态。虽然大部分系统提供了用于维持某些状态的方法，但流处理主要针对副作用更少，更加功能性的处理（Functional processing）进行优化。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">功能性操作主要侧重于状态或副作用有限的离散步骤。针对同一个数据执行同一个操作会或略其他因素产生相同的结果，此类处理非常适合流处理，因为不同项的状态通常是某些困难、限制，以及某些情况下不需要的结果的结合体。因此虽然某些类型的状态管理通常是可行的，但这些框架通常在不具备状态管理机制时更简单也更高效。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">此类处理非常适合某些类型的工作负载。有近实时处理需求的任务很适合使用流处理模式。分析、服务器或应用程序错误日志，以及其他基于时间的衡量指标是最适合的类型，因为对这些领域的数据变化做出响应对于业务职能来说是极为关键的。流处理很适合用来处理必须对变动或峰值做出响应，并且关注一段时间内变化趋势的数据。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>Apache Storm</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Apache Storm是一种侧重于极低延迟的流处理框架，也许是要求近实时处理的工作负载的最佳选择。该技术可处理非常大量的数据，通过比其他解决方案更低的延迟提供结果。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>流处理模式</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Storm的流处理可对框架中名为Topology（拓扑）的DAG（Directed Acyclic Graph，有向无环图）进行编排。这些拓扑描述了当数据片段进入系统后，需要对每个传入的片段执行的不同转换或步骤。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">拓扑包含：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>Stream：普通的数据流，这是一种会持续抵达系统的无边界数据。</p></li><li><p>Spout：位于拓扑边缘的数据流来源，例如可以是API或查询等，从这里可以产生待处理的数据。</p></li><li><p>Bolt：Bolt代表需要消耗流数据，对其应用操作，并将结果以流的形式进行输出的处理步骤。Bolt需要与每个Spout建立连接，随后相互连接以组成所有必要的处理。在拓扑的尾部，可以使用最终的Bolt输出作为相互连接的其他系统的输入。</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Storm背后的想法是使用上述组件定义大量小型的离散操作，随后将多个组件组成所需拓扑。默认情况下Storm提供了“至少一次”的处理保证，这意味着可以确保每条消息至少可以被处理一次，但某些情况下如果遇到失败可能会处理多次。Storm无法确保可以按照特定顺序处理消息。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">为了实现严格的一次处理，即有状态处理，可以使用一种名为Trident的抽象。严格来说不使用Trident的Storm通常可称之为Core Storm。Trident会对Storm的处理能力产生极大影响，会增加延迟，为处理提供状态，使用微批模式代替逐项处理的纯粹流处理模式。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">为避免这些问题，通常建议Storm用户尽可能使用Core Storm。然而也要注意，Trident对内容严格的一次处理保证在某些情况下也比较有用，例如系统无法智能地处理重复消息时。如果需要在项之间维持状态，例如想要计算一个小时内有多少用户点击了某个链接，此时Trident将是你唯一的选择。尽管不能充分发挥框架与生俱来的优势，但Trident提高了Storm的灵活性。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Trident拓扑包含：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>流批（Stream batch）：这是指流数据的微批，可通过分块提供批处理语义。</p></li><li><p>操作（Operation）：是指可以对数据执行的批处理过程。</p></li></ul><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>优势和局限</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">目前来说Storm可能是近实时处理领域的最佳解决方案。该技术可以用极低延迟处理数据，可用于希望获得最低延迟的工作负载。如果处理速度直接影响用户体验，例如需要将处理结果直接提供给访客打开的网站页面，此时Storm将会是一个很好的选择。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Storm与Trident配合使得用户可以用微批代替纯粹的流处理。虽然借此用户可以获得更大灵活性打造更符合要求的工具，但同时这种做法会削弱该技术相比其他解决方案最大的优势。话虽如此，但多一种流处理方式总是好的。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Core Storm无法保证消息的处理顺序。Core Storm为消息提供了“至少一次”的处理保证，这意味着可以保证每条消息都能被处理，但也可能发生重复。Trident提供了严格的一次处理保证，可以在不同批之间提供顺序处理，但无法在一个批内部实现顺序处理。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">在互操作性方面，Storm可与Hadoop的YARN资源管理器进行集成，因此可以很方便地融入现有Hadoop部署。除了支持大部分处理框架，Storm还可支持多种语言，为用户的拓扑定义提供了更多选择。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>总结</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">对于延迟需求很高的纯粹的流处理工作负载，Storm可能是最适合的技术。该技术可以保证每条消息都被处理，可配合多种编程语言使用。由于Storm无法进行批处理，如果需要这些能力可能还需要使用其他软件。如果对严格的一次处理保证有比较高的要求，此时可考虑使用Trident。不过这种情况下其他流处理框架也许更适合。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>Apache Samza</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Apache Samza是一种与Apache Kafka消息系统紧密绑定的流处理框架。虽然Kafka可用于很多流处理系统，但按照设计，Samza可以更好地发挥Kafka独特的架构优势和保障。该技术可通过Kafka提供容错、缓冲，以及状态存储。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Samza可使用YARN作为资源管理器。这意味着默认情况下需要具备Hadoop集群（至少具备HDFS和YARN），但同时也意味着Samza可以直接使用YARN丰富的内建功能。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>流处理模式</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Samza依赖Kafka的语义定义流的处理方式。Kafka在处理数据时涉及下列概念：</p><ul style=\"box-sizing: border-box; margin-bottom: 16px; padding: 0px 0px 0px 2em; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\" class=\" list-paddingleft-2\"><li><p>Topic（话题）：进入Kafka系统的每个数据流可称之为一个话题。话题基本上是一种可供消耗方订阅的，由相关信息组成的数据流。</p></li><li><p>Partition（分区）：为了将一个话题分散至多个节点，Kafka会将传入的消息划分为多个分区。分区的划分将基于键（Key）进行，这样可以保证包含同一个键的每条消息可以划分至同一个分区。分区的顺序可获得保证。</p></li><li><p>Broker（代理）：组成Kafka集群的每个节点也叫做代理。</p></li><li><p>Producer（生成方）：任何向Kafka话题写入数据的组件可以叫做生成方。生成方可提供将话题划分为分区所需的键。</p></li><li><p>Consumer（消耗方）：任何从Kafka读取话题的组件可叫做消耗方。消耗方需要负责维持有关自己分支的信息，这样即可在失败后知道哪些记录已经被处理过了。</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">由于Kafka相当于永恒不变的日志，Samza也需要处理永恒不变的数据流。这意味着任何转换创建的新数据流都可被其他组件所使用，而不会对最初的数据流产生影响。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>优势和局限</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">乍看之下，Samza对Kafka类查询系统的依赖似乎是一种限制，然而这也可以为系统提供一些独特的保证和功能，这些内容也是其他流处理系统不具备的。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">例如Kafka已经提供了可以通过低延迟方式访问的数据存储副本，此外还可以为每个数据分区提供非常易用且低成本的多订阅者模型。所有输出内容，包括中间态的结果都可写入到Kafka，并可被下游步骤独立使用。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">这种对Kafka的紧密依赖在很多方面类似于MapReduce引擎对HDFS的依赖。虽然在批处理的每个计算之间对HDFS的依赖导致了一些严重的性能问题，但也避免了流处理遇到的很多其他问题。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Samza与Kafka之间紧密的关系使得处理步骤本身可以非常松散地耦合在一起。无需事先协调，即可在输出的任何步骤中增加任意数量的订阅者，对于有多个团队需要访问类似数据的组织，这一特性非常有用。多个团队可以全部订阅进入系统的数据话题，或任意订阅其他团队对数据进行过某些处理后创建的话题。这一切并不会对数据库等负载密集型基础架构造成额外的压力。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">直接写入Kafka还可避免回压（Backpressure）问题。回压是指当负载峰值导致数据流入速度超过组件实时处理能力的情况，这种情况可能导致处理工作停顿并可能丢失数据。按照设计，Kafka可以将数据保存很长时间，这意味着组件可以在方便的时候继续进行处理，并可直接重启动而无需担心造成任何后果。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Samza可以使用以本地键值存储方式实现的容错检查点系统存储数据。这样Samza即可获得“至少一次”的交付保障，但面对由于数据可能多次交付造成的失败，该技术无法对汇总后状态（例如计数）提供精确恢复。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Samza提供的高级抽象使其在很多方面比Storm等系统提供的基元（Primitive）更易于配合使用。目前Samza只支持JVM语言，这意味着它在语言支持方面不如Storm灵活。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>总结</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">对于已经具备或易于实现Hadoop和Kafka的环境，Apache Samza是流处理工作负载一个很好的选择。Samza本身很适合有多个团队需要使用（但相互之间并不一定紧密协调）不同处理阶段的多个数据流的组织。Samza可大幅简化很多流处理工作，可实现低延迟的性能。如果部署需求与当前系统不兼容，也许并不适合使用，但如果需要极低延迟的处理，或对严格的一次处理语义有较高需求，此时依然适合考虑。</p><h3 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.43; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.5em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>混合处理系统：批处理和流处理</h3><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">一些处理框架可同时处理批处理和流处理工作负载。这些框架可以用相同或相关的组件和API处理两种类型的数据，借此让不同的处理需求得以简化。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">如你所见，这一特性主要是由Spark和Flink实现的，下文将介绍这两种框架。实现这样的功能重点在于两种不同处理模式如何进行统一，以及要对固定和不固定数据集之间的关系进行何种假设。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">虽然侧重于某一种处理类型的项目会更好地满足具体用例的要求，但混合框架意在提供一种数据处理的通用解决方案。这种框架不仅可以提供处理数据所需的方法，而且提供了自己的集成项、库、工具，可胜任图形分析、机器学习、交互式查询等多种任务。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; line-height: 1.4; color: rgb(51, 51, 51); margin-top: 1em; margin-bottom: 16px; font-size: 1.25em; position: relative; white-space: normal;\"><a class=\"reference-link\" style=\"box-sizing: border-box; background-image: initial; background-position: 0px 0px; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; color: rgb(65, 131, 196);\"></a>Apache Spark</h4><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\"><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098095802051309.jpg\" alt=\"\"/></p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Apache Spark是一种包含流处理能力的下一代批处理框架。与Hadoop的MapReduce引擎基于各种相同原则开发而来的Spark主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">Spark可作为独立集群部署（需要相应存储层的配合），或可与Hadoop集成并取代MapReduce引擎。</p><h4 style=\"box-sizing: border-box; font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe','<p style=\"box-sizing: border-box; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal; margin-top: 0px !important;\">大数据是收集、整理、处理大容量数据集，并从中获得见解所需的非传统战略和技术的总称。虽然处理数据所需的计算能力或存储容量早已超过一台计算机的上限，但这种计算类型的普遍性、规模，以及价值在最近几年才经历了大规模扩展。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">在之前的文章中，我们曾经介绍过有关大数据系统的常规概念、处理过程，以及各种专门术语，本文将介绍大数据系统一个最基本的组件：处理框架。处理框架负责对系统中的数据进行计算，例如处理从非易失存储中读取的数据，或处理刚刚摄入到系统中的数据。数据的计算则是指从大量单一数据点中提取信息和见解的过程。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &quot;Microsoft YaHei&quot;, Helvetica, &quot;Meiryo UI&quot;, &quot;Malgun Gothic&quot;, &quot;Segoe UI&quot;, &quot;Trebuchet MS&quot;, Monaco, monospace, Tahoma, STXihei, 华文细黑, STHeiti, &quot;Helvetica Neue&quot;, &quot;Droid Sans&quot;, &quot;wenquanyi micro hei&quot;, FreeSans, Arimo, Arial, SimSun, 宋体, Heiti, 黑体, sans-serif; font-size: 14px; white-space: normal;\">下文将介绍这些框架：</p>',2,NULL),(100020,'mosquito','微分享：Spark基础入门介绍','2017-06-22 10:26:56','2017-06-22','spark','技术','<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">提到大数据技术，大多数开发者首先想到的技术莫过于Hadoop和Spark。他们都是大数据框架，也是当前应用最广泛的大数据框架。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">4月11晚8点（本周二），CSDN大数据学习班将迎来咱们的第二期知识大咖分享活动，主要分享开源的Spark大数据技术。&nbsp;<br/>分享嘉宾：叶帅</p><blockquote style=\"box-sizing: border-box; padding: 10px 20px; margin: 10px 0px; font-size: 14px; border-left: 5px solid rgba(128, 128, 128, 0.075); background: rgb(247, 247, 247); color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal;\"><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 0px;\">叶帅 毕业于东华大学，研究方向为数据科学，目前就职于小i机器人，主要负责Hadoop、Spark集群搭建和维护，大数据分析和数据挖掘，Hive数据仓库和数据建模。Job和日志数据管理等工作&nbsp;<br/>以下为昨晚的分享总结：</p></blockquote><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">本次分享主题是Spark入门，既然是入门，就涉及Spark的部署和基本概念的理解，这也是我们进一步深入理解Spark的基础。&nbsp;<br/>首先是部署环节：&nbsp;<br/>1.先安装，HDFS的namenode,secondaryNamenode, datanode&nbsp;<br/>Spark的master和worker进程；&nbsp;<br/>Master负责分配资源，在集群启动时，Driver向Master申请资源，Worker负责监控自己节点的内存和CPU等状况，并向Master汇报。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389275027445.png\" alt=\"图片描述\" title=\"\"/><br/>2.Cluster模型：Spark Application的组成部分&nbsp;<br/>一个Worker默认情况下分配一个Executor，配置时根据需要也可以配置多个Executor。一个节点，如果配置了多个Executor，那么就会涉及到性能调优。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389380061736.png\" alt=\"图片描述\" title=\"\"/><br/>3.standalone的运行模式：&nbsp;<br/>组成cluster的两大元素即Master和Worker。slave worker可以有1到多个，这些worker都处于active状态。&nbsp;<br/>Driver Application可以运行在Cluster之内，也可以在cluster之外运行，先从简单的讲起即Driver Application独立于Cluster。那么这样的整体框架如上图所示，由driver，master和多个slave worker来共同组成整个的运行环境。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389523086004.png\" alt=\"图片描述\" title=\"\"/><br/>4.Spark Runtime&nbsp;<br/>Driver进程启动多个worker进程，worker从HDFS读取Block，然后将RDD分片保存在内存中能计算。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389602001185.png\" alt=\"图片描述\" title=\"\"/><br/>5.来一个wordcount程序：</p><pre class=\"prettyprint\" style=\"box-sizing: border-box; overflow: auto; font-family: &quot;Source Code Pro&quot;, monospace; font-size: 13px; padding: 9.5px; margin-top: 0px; margin-bottom: 10px; line-height: 1.45; color: rgb(51, 51, 51); word-break: break-all; word-wrap: break-word; background-color: rgb(248, 249, 250); border: 1px solid rgba(128, 128, 128, 0.075); border-radius: 0px; text-align: justify;\">object&nbsp;WordCount&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;main(args:&nbsp;Array[String])&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;inputFile&nbsp;=&nbsp;args(0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;outputFile&nbsp;=&nbsp;args(1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;conf&nbsp;=&nbsp;new&nbsp;SparkConf().setAppName(&quot;wordCount&quot;)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;a&nbsp;Scala&nbsp;Spark&nbsp;Context.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sc&nbsp;=&nbsp;new&nbsp;SparkContext(conf)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Load&nbsp;our&nbsp;input&nbsp;data.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;input&nbsp;=&nbsp;&nbsp;sc.textFile(inputFile)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Split&nbsp;up&nbsp;into&nbsp;words.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;words&nbsp;=&nbsp;input.flatMap(line&nbsp;=&gt;&nbsp;line.split(&quot;&nbsp;&quot;))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Transform&nbsp;into&nbsp;word&nbsp;and&nbsp;count.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;counts&nbsp;=&nbsp;words.map(word&nbsp;=&gt;&nbsp;(word,&nbsp;1)).reduceByKey{case&nbsp;(x,&nbsp;y)&nbsp;=&gt;&nbsp;x&nbsp;+&nbsp;y}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Save&nbsp;the&nbsp;word&nbsp;count&nbsp;back&nbsp;out&nbsp;to&nbsp;a&nbsp;text&nbsp;file,&nbsp;causing&nbsp;evaluation.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;counts.saveAsTextFile(outputFile)\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}</pre><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">6.Job的内部运行机制&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389708032845.png\" alt=\"图片描述\" title=\"\"/><br/>7.RDD宽依赖和窄依赖的例子</p><ul style=\"box-sizing: border-box; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\" class=\" list-paddingleft-2\"><li><p>窄依赖：父RDD的每个分片基本都被子RDD的一个分片所利用。</p></li><li><p>宽依赖：父RDD的每个分片被多个子RDD分片依赖。</p></li></ul><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">这里每个蓝色方框都是一个RDD，外边的长方形是分片。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098389896054178.png\" alt=\"图片描述\" title=\"\"/><br/>8.Job Stage&nbsp;<br/>任务调度，黑色部分代表RDD在内存中。基于RDD的G是一个action操作，引起跨stage的宽依赖和一个stage中的窄依赖转换（pipeline transformation）。Stage的虚线是宽依赖所需要的shuffle操作。只有有一个task计算失败，只要还有父RDD，就在其他节点上重新计算。&nbsp;<br/><img src=\"/blog/ueditor/jsp/upload/image/20170622/1498098390004098936.png\" alt=\"图片描述\" title=\"\"/></p><p><br/></p>','<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">提到大数据技术，大多数开发者首先想到的技术莫过于Hadoop和Spark。他们都是大数据框架，也是当前应用最广泛的大数据框架。</p><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal; background-color: rgb(255, 255, 255);\">4月11晚8点（本周二），CSDN大数据学习班将迎来咱们的第二期知识大咖分享活动，主要分享开源的Spark大数据技术。&nbsp;<br/>分享嘉宾：叶帅</p><blockquote style=\"box-sizing: border-box; padding: 10px 20px; margin: 10px 0px; font-size: 14px; border-left: 5px solid rgba(128, 128, 128, 0.075); background: rgb(247, 247, 247); color: rgb(51, 51, 51); font-family: &quot;microsoft yahei&quot;, arial; text-align: justify; white-space: normal;\"><p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 0px;\">叶帅 毕业于东华大学，研究方向为数据科学，目前就职于小i机器人，主要负责Hadoop、Spark集群搭建和维护，大数据分析和数据挖掘，Hive数据仓库和数据建模。Job和日志数据管理等工作&nbsp;<br/>以下为昨晚的分享总结：</p>',0,NULL);

/*Table structure for table `comments` */

DROP TABLE IF EXISTS `comments`;

CREATE TABLE `comments` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `commentid` int(11) DEFAULT NULL COMMENT '被评论的id',
  `userid` int(11) DEFAULT NULL COMMENT '用户id',
  `commtime` datetime DEFAULT NULL COMMENT '评论时间',
  `content` varchar(300) COLLATE utf8_bin DEFAULT NULL COMMENT '评论内容',
  `category` char(20) COLLATE utf8_bin DEFAULT NULL COMMENT '类别',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=32 DEFAULT CHARSET=utf8 COLLATE=utf8_bin;

/*Data for the table `comments` */

insert  into `comments`(`id`,`commentid`,`userid`,`commtime`,`content`,`category`) values (2,100000,1,'2017-06-20 00:00:00','这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！','1'),(3,2,1,'2017-06-20 00:00:00','这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！','2'),(4,100001,1,'2017-06-20 00:00:00','这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！','1'),(5,2,1,'2017-06-20 00:00:00','这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！这里是评论！','2'),(8,0,5,'2017-06-21 08:10:09','测试数据测试数据测试数据测试数据测试数据测试数据','1'),(25,2,3,'2017-06-21 08:53:55','验证功能','2'),(26,2,2,'2017-06-21 08:54:21','我也来试一把','2'),(27,2,2,'2017-06-21 08:55:31','再次验证','2'),(28,100000,3,'2017-06-21 08:58:28','验证效果','1'),(29,2,3,'2017-06-21 09:00:43','是不是呐','2'),(30,100008,2,'2017-06-21 19:37:01','我来评论一下','1'),(31,100010,2,'2017-06-21 19:55:01','来一条评论','1');

/*Table structure for table `user` */

DROP TABLE IF EXISTS `user`;

CREATE TABLE `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `username` varchar(50) DEFAULT NULL COMMENT '昵称',
  `email` varchar(30) DEFAULT NULL COMMENT '邮箱',
  `password` varchar(20) DEFAULT NULL COMMENT '密码',
  `rule` varchar(20) DEFAULT NULL COMMENT '角色',
  `headpic` varchar(50) DEFAULT NULL COMMENT '头像',
  `selfintroduction` varchar(200) DEFAULT NULL COMMENT '自我介绍',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;

/*Data for the table `user` */

insert  into `user`(`id`,`username`,`email`,`password`,`rule`,`headpic`,`selfintroduction`) values (1,'admin','admin@email.com','123456','1','img/avatar.png','自我介绍'),(2,'张三','test@test.com','111111','2','img/head1.PNG',''),(3,'李四','test@test.com','111111','2','img/head2.PNG',''),(4,'王五','test@test.com','111111','2','img/head3.PNG',''),(5,'战三',NULL,'','2','img/head1.PNG','asdfghjk');

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;
